{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hessian_reg_RNN_04022021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-pI5OAv7jzk",
        "outputId": "d07a6b2a-0532-4aa8-d083-e6f07e97372b"
      },
      "source": [
        "!git clone https://github.com/wpeebles/hessian_penalty.git\r\n",
        "!git clone https://github.com/Harry24k/adversairal-attacks-pytorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hessian_penalty'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 195 (delta 15), reused 91 (delta 15), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (195/195), 44.26 MiB | 40.29 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Cloning into 'adversairal-attacks-pytorch'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 1024 (delta 8), reused 7 (delta 1), pack-reused 996\u001b[K\n",
            "Receiving objects: 100% (1024/1024), 36.31 MiB | 38.21 MiB/s, done.\n",
            "Resolving deltas: 100% (590/590), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfif2nyq7cXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63028da8-554c-4a92-b053-9ab817955500"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
        "\n",
        "import sys\n",
        "#sys.path.append(r\"C:\\Users\\peter fazekas\\Desktop\\masters\\RNN hessian reg\\hessian_penalty-master\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxIFxcCZ7cXX"
      },
      "source": [
        "from hessian_penalty.hessian_penalty_pytorch import hessian_penalty"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN9Hek1b7cXX",
        "outputId": "0c301e29-eb48-48da-c15e-561baf8dce55"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "print(\"original shape: \",X_train.shape)\n",
        "X= X_train\n",
        "print(\"shape needed for RNN: \",X.shape)\n",
        "print(\"ytrains shape\",y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original shape:  (60000, 28, 28)\n",
            "shape needed for RNN:  (60000, 28, 28)\n",
            "ytrains shape (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXHSYK4b7cXY"
      },
      "source": [
        "# parameters \n",
        "N_STEPS = 28\n",
        "N_INPUTS = 28\n",
        "N_NEURONS = 150\n",
        "N_OUTPUTS = 10\n",
        "N_EPHOCS = 30\n",
        "BATCH_SIZE=128"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqA10-xv7cXZ"
      },
      "source": [
        "\n",
        "\n",
        "# list all transformations\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# download and load training dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# download and load testing dataset\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H3420Yw7cXZ"
      },
      "source": [
        "# RNN Model\n",
        "class ImageRNN(nn.Module):\n",
        "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
        "        super(ImageRNN, self).__init__()\n",
        "        \n",
        "        self.n_neurons = n_neurons\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "        self.device =\"cuda:0\"\n",
        "        \n",
        "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
        "        \n",
        "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
        "        \n",
        "    def init_hidden(self,):\n",
        "        # (num_layers, batch_size, n_neurons)\n",
        "        return (torch.zeros(1, self.batch_size, self.n_neurons).to(self.device))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
        "        X = X.permute(1, 0, 2) \n",
        "        \n",
        "        \n",
        "        self.batch_size = X.size(1)\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
        "        out = self.FC(self.hidden)\n",
        "        \n",
        "        return out.view(-1, self.n_outputs) # batch_size X n_output\n",
        "#model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJQ3yTv__jf6",
        "outputId": "bbf1d826-1439-4d89-c0c6-3f011a063d14"
      },
      "source": [
        "print(\"GPU is:\",torch.cuda.get_device_name(0))\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is: Tesla T4\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL853zNZvS8f"
      },
      "source": [
        ""
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCjV4UQW7cXa"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()\n",
        "#reg = hessian_penalty()\n",
        "lambda_JR = 0.01 # hyperparameter\n",
        "\n",
        "def train(jacobi,model,N_EPHOCS,lambda_JR):\n",
        "    # Model instance\n",
        "\n",
        "    for epoch in range(N_EPHOCS+1):  # loop over the dataset multiple times\n",
        "        train_running_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        model.train()\n",
        "        # TRAINING ROUND\n",
        "        for i, data in enumerate(trainloader,0):\n",
        "            #only train for a single batch for now since its faster\n",
        "            if i>=1:\n",
        "              break\n",
        "             # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # reset hidden states\n",
        "            model.hidden = model.init_hidden()\n",
        "            \n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            inputs = inputs.view(-1,28, 28) \n",
        "            inputs.requires_grad = True # this is essential!\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            #print(inputs.shape)\n",
        "            outputs = model(inputs)\n",
        "            #print(\"output shape is \", outputs.shape)\n",
        "            loss = criterion(outputs, labels)\n",
        "               # hessian regularization\n",
        "            if not jacobi:\n",
        "                total_loss = loss \n",
        "                R=hessian_penalty(model,z =inputs).cuda()\n",
        "            else:\n",
        "                R = hessian_penalty(model,z =inputs).cuda()\n",
        "                total_loss = loss +lambda_JR*(R) # full loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_running_loss += loss.detach().item()\n",
        "            train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "        model.eval()\n",
        "        #print(i)\n",
        "        if epoch%10==0:\n",
        "          print('Epoch:  %d | Loss: %.4f |hessian Loss %.4f | Train Accuracy: %.2f' \n",
        "                %(epoch, train_running_loss/i,R, train_acc/i))\n",
        "        \n",
        "        \n",
        "    "
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VnClm5feuE_"
      },
      "source": [
        "models = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS).cuda()\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(models.parameters(), lr=0.001)\r\n",
        "model_NH = models.to(device)\r\n",
        "if torch.cuda.is_available():\r\n",
        "  model_NH =model_NH.cuda()\r\n",
        "  criterion=criterion.cuda()"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml6JrCWyb13A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "e1873a2c-a3cb-43e5-cdca-9f7ea0aff814"
      },
      "source": [
        "print(\"training without hessian reg\")\r\n",
        "N_EPHOCS=300\r\n",
        "optimizer = optim.Adam(models.parameters(), lr=0.001)\r\n",
        "train(False,model_NH,N_EPHOCS,lambda_JR)\r\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training without hessian reg\n",
            "Epoch:  0 | Loss: 2.3166 |hessian Loss 0.0031 | Train Accuracy: 7.81\n",
            "Epoch:  10 | Loss: 1.9951 |hessian Loss 2.8894 | Train Accuracy: 27.34\n",
            "Epoch:  20 | Loss: 1.5694 |hessian Loss 22394.8105 | Train Accuracy: 45.31\n",
            "Epoch:  30 | Loss: 1.3036 |hessian Loss 30894.6777 | Train Accuracy: 59.38\n",
            "Epoch:  40 | Loss: 1.1293 |hessian Loss 118014.1719 | Train Accuracy: 64.84\n",
            "Epoch:  50 | Loss: 1.0017 |hessian Loss 75535.4844 | Train Accuracy: 68.75\n",
            "Epoch:  60 | Loss: 0.8831 |hessian Loss 172673.3125 | Train Accuracy: 68.75\n",
            "Epoch:  70 | Loss: 0.8002 |hessian Loss 92553.3438 | Train Accuracy: 71.88\n",
            "Epoch:  80 | Loss: 0.7770 |hessian Loss 289685.6875 | Train Accuracy: 69.53\n",
            "Epoch:  90 | Loss: 0.6458 |hessian Loss 410869.2500 | Train Accuracy: 81.25\n",
            "Epoch:  100 | Loss: 0.5898 |hessian Loss 270961.8438 | Train Accuracy: 81.25\n",
            "Epoch:  110 | Loss: 0.5441 |hessian Loss 331847.6562 | Train Accuracy: 83.59\n",
            "Epoch:  120 | Loss: 0.4908 |hessian Loss 359065.1250 | Train Accuracy: 85.16\n",
            "Epoch:  130 | Loss: 0.6875 |hessian Loss 329377.1250 | Train Accuracy: 76.56\n",
            "Epoch:  140 | Loss: 0.4564 |hessian Loss 660436.3125 | Train Accuracy: 85.94\n",
            "Epoch:  150 | Loss: 0.4056 |hessian Loss 896770.2500 | Train Accuracy: 88.28\n",
            "Epoch:  160 | Loss: 0.3604 |hessian Loss 1192025.1250 | Train Accuracy: 92.97\n",
            "Epoch:  170 | Loss: 0.3192 |hessian Loss 457997.9375 | Train Accuracy: 92.97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-f59b6da7c2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mN_EPHOCS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_NH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_EPHOCS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_JR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-136-838e10b5ca71>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(jacobi, model, N_EPHOCS, lambda_JR)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# TRAINING ROUND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m#only train for a single batch for now since its faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbJJrt3Rb0RU",
        "outputId": "3550faee-e747-4c78-c47f-2c5f129379f7"
      },
      "source": [
        "print(\"training with hessian reg\")\r\n",
        "#reset the model and train with hessian reg\r\n",
        "models = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS).cuda()\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(models.parameters(), lr=0.0001)\r\n",
        "model_H = models.to(device)\r\n",
        "if torch.cuda.is_available():\r\n",
        "  model_H =model_H.cuda()\r\n",
        "  criterion=criterion.cuda()\r\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training with hessian reg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "8Xybbc6UkY_S",
        "outputId": "0f229027-841c-4008-9ea7-629715dd52e6"
      },
      "source": [
        "#sometimes it gets stuck in local minima so change learning rate, accuracy should be above 80%\r\n",
        "optimizer = optim.Adam(models.parameters(), lr=0.001)\r\n",
        "train(True,model_H,N_EPHOCS=1000,lambda_JR=0.01)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | Loss: 2.3041 |hessian Loss 0.0029 | Train Accuracy: 14.06\n",
            "Epoch:  10 | Loss: 2.0532 |hessian Loss 0.4981 | Train Accuracy: 36.72\n",
            "Epoch:  20 | Loss: 1.7431 |hessian Loss 4.6121 | Train Accuracy: 47.66\n",
            "Epoch:  30 | Loss: 1.5015 |hessian Loss 17.7610 | Train Accuracy: 51.56\n",
            "Epoch:  40 | Loss: 1.4061 |hessian Loss 4.6988 | Train Accuracy: 56.25\n",
            "Epoch:  50 | Loss: 1.6545 |hessian Loss 7.8400 | Train Accuracy: 40.62\n",
            "Epoch:  60 | Loss: 1.4239 |hessian Loss 19.7812 | Train Accuracy: 60.16\n",
            "Epoch:  70 | Loss: 1.3718 |hessian Loss 6.4652 | Train Accuracy: 62.50\n",
            "Epoch:  80 | Loss: 1.2517 |hessian Loss 7.1515 | Train Accuracy: 64.06\n",
            "Epoch:  90 | Loss: 1.2813 |hessian Loss 5.0980 | Train Accuracy: 60.94\n",
            "Epoch:  100 | Loss: 1.1511 |hessian Loss 23.9883 | Train Accuracy: 64.84\n",
            "Epoch:  110 | Loss: 1.1914 |hessian Loss 4.6314 | Train Accuracy: 66.41\n",
            "Epoch:  120 | Loss: 1.0685 |hessian Loss 9.0660 | Train Accuracy: 71.88\n",
            "Epoch:  130 | Loss: 1.2005 |hessian Loss 13.1593 | Train Accuracy: 62.50\n",
            "Epoch:  140 | Loss: 1.1961 |hessian Loss 7.1417 | Train Accuracy: 66.41\n",
            "Epoch:  150 | Loss: 1.1730 |hessian Loss 8.1449 | Train Accuracy: 71.88\n",
            "Epoch:  160 | Loss: 0.9346 |hessian Loss 16.6296 | Train Accuracy: 74.22\n",
            "Epoch:  170 | Loss: 1.0321 |hessian Loss 16.3826 | Train Accuracy: 71.09\n",
            "Epoch:  180 | Loss: 1.1570 |hessian Loss 9.1821 | Train Accuracy: 69.53\n",
            "Epoch:  190 | Loss: 1.0295 |hessian Loss 6.1184 | Train Accuracy: 73.44\n",
            "Epoch:  200 | Loss: 0.9793 |hessian Loss 6.4023 | Train Accuracy: 71.88\n",
            "Epoch:  210 | Loss: 0.9710 |hessian Loss 5.7302 | Train Accuracy: 71.09\n",
            "Epoch:  220 | Loss: 1.0211 |hessian Loss 15.1887 | Train Accuracy: 64.84\n",
            "Epoch:  230 | Loss: 1.0177 |hessian Loss 14.5709 | Train Accuracy: 74.22\n",
            "Epoch:  240 | Loss: 0.8311 |hessian Loss 17.3368 | Train Accuracy: 76.56\n",
            "Epoch:  250 | Loss: 0.9576 |hessian Loss 9.7837 | Train Accuracy: 71.88\n",
            "Epoch:  260 | Loss: 0.7910 |hessian Loss 16.6844 | Train Accuracy: 79.69\n",
            "Epoch:  270 | Loss: 0.8680 |hessian Loss 26.6977 | Train Accuracy: 76.56\n",
            "Epoch:  280 | Loss: 0.7878 |hessian Loss 14.5491 | Train Accuracy: 79.69\n",
            "Epoch:  290 | Loss: 0.8561 |hessian Loss 24.0508 | Train Accuracy: 78.91\n",
            "Epoch:  300 | Loss: 0.8139 |hessian Loss 13.8988 | Train Accuracy: 78.91\n",
            "Epoch:  310 | Loss: 0.8186 |hessian Loss 12.4563 | Train Accuracy: 80.47\n",
            "Epoch:  320 | Loss: 0.8401 |hessian Loss 16.8464 | Train Accuracy: 75.00\n",
            "Epoch:  330 | Loss: 0.7741 |hessian Loss 13.1334 | Train Accuracy: 82.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-dacf91571b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#sometimes it gets stuck in local minima so change learning rate, accuracy should be above 80%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_EPHOCS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_JR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-136-838e10b5ca71>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(jacobi, model, N_EPHOCS, lambda_JR)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# TRAINING ROUND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m#only train for a single batch for now since its faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZtNfUtjNsNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928a082c-1819-4d6f-ac89-04e02faa766b"
      },
      "source": [
        "import random\r\n",
        "for i, data in enumerate(trainloader,0):\r\n",
        "      if i>=1:\r\n",
        "        break\r\n",
        "      inputs, labels = data\r\n",
        "      if torch.cuda.is_available():\r\n",
        "            inputs = inputs.cuda()\r\n",
        "            labels = labels.cuda()\r\n",
        "      print(type(inputs))\r\n",
        "      inputs = inputs.view(-1,28, 28)\r\n",
        "      accNH = get_accuracy(model_NH(inputs),labels,BATCH_SIZE)\r\n",
        "      print(\"accuracy without hessian on training data\",accNH)\r\n",
        "      accH = get_accuracy(model_H(inputs),labels,BATCH_SIZE)\r\n",
        "      print(\"accuracy with hessian on training data\",accH)\r\n",
        "      "
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "accuracy without hessian on training data 93.75\n",
            "accuracy with hessian on training data 82.03125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh_-klHaQHzW",
        "outputId": "db19684f-7411-49b7-f6d5-bbd99f967849"
      },
      "source": [
        "from adversairal import torchattacks\r\n",
        "\r\n",
        "for i, data in enumerate(trainloader,0):\r\n",
        "  if i>=1:\r\n",
        "    break\r\n",
        "  torch.backends.cudnn.enabled = False\r\n",
        "  if torch.cuda.is_available():\r\n",
        "        inputs = inputs.cuda()\r\n",
        "        labels = labels.cuda()\r\n",
        "  inputs, labels = data\r\n",
        "  inputs = inputs.view(-1,28, 28) \r\n",
        "  inputs.requires_grad = True # this is essential!\r\n",
        "  atk_H = torchattacks.PGD(model_H, eps=10/255, alpha=2/255, steps=3)\r\n",
        "  atk_NH = torchattacks.PGD(model_NH, eps=10/255, alpha=2/255, steps=3)\r\n",
        "  adversarial_images_H = atk_H(inputs, labels)\r\n",
        "  adversarial_images_NH = atk_NH(inputs, labels)\r\n",
        "  adversarial_labels = labels\r\n",
        "  if torch.cuda.is_available():\r\n",
        "        inputs = inputs.cuda()\r\n",
        "        labels = labels.cuda()\r\n",
        "        adversarial_images = adversarial_images.cuda()\r\n",
        "        adversarial_labels = adversarial_labels.cuda()\r\n",
        "        model_NH=model_NH.cuda()\r\n",
        "        model_H=model_H.cuda()\r\n",
        "  accNH = get_accuracy(model_NH(adversarial_images_NH),adversarial_labels,BATCH_SIZE)\r\n",
        "  print(\"accuracy without hessian on adversarial data\",accNH)\r\n",
        "  print(\"difference in accuracy without hessian\",abs(accNH-get_accuracy(model_NH(inputs),labels,BATCH_SIZE)))\r\n",
        "  print(\"\\n\")\r\n",
        "  accH = get_accuracy(model_H(adversarial_images_H),adversarial_labels,BATCH_SIZE)\r\n",
        "  print(\"accuracy with hessian on adversarial data\",accH)\r\n",
        "  print(\"difference in accuracy with hessian\",abs(accH-get_accuracy(model_H(inputs),labels,BATCH_SIZE)))\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy without hessian on adversarial data 21.875\n",
            "difference in accuracy without hessian 71.875\n",
            "\n",
            "\n",
            "accuracy with hessian on adversarial data 76.5625\n",
            "difference in accuracy with hessian 5.46875\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVsoez1-CTb6"
      },
      "source": [
        "**Adversarial attacks with random perturb**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEs2V4nq8rTG",
        "outputId": "7c5ffa27-47f4-48f4-c4cf-f8536b2c4d66"
      },
      "source": [
        "\r\n",
        "from adversairal import torchattacks\r\n",
        "global inputs,labels\r\n",
        "for i, data in enumerate(trainloader,0):\r\n",
        "  #train for 1 batches\r\n",
        "  if i>=1:\r\n",
        "    break\r\n",
        "  torch.backends.cudnn.enabled = False\r\n",
        "  if torch.cuda.is_available():\r\n",
        "        inputs = inputs.cuda()\r\n",
        "        labels = labels.cuda()\r\n",
        "  inputs, labels = data\r\n",
        "  orig_in,orig_lab=inputs,labels\r\n",
        "  inputs = inputs.view(-1,28, 28) \r\n",
        "  orig_in = orig_in.view(-1,28,28)\r\n",
        "  inputs.requires_grad = True # this is essential!\r\n",
        "  p_inputs = inputs\r\n",
        "  p_inputs.requires_grad = False\r\n",
        "  p_labels = labels\r\n",
        "  \r\n",
        "  for k in range(p_inputs.shape[0]):\r\n",
        "    #sample set of points and then divide by the norm of it\r\n",
        "    #np.random.seed(1)\r\n",
        "    vecs = np.random.uniform(-1,1,(1,p_inputs.shape[1],p_inputs.shape[2]))\r\n",
        "    vecs/= np.linalg.norm(vecs)\r\n",
        "    vecs=0.1*vecs\r\n",
        "    #print(vecs)       \r\n",
        "    vecs = torch.from_numpy(vecs).cuda()\r\n",
        "    p_inputs[k] = torch.add(p_inputs[k].cuda(),vecs)\r\n",
        "  inputs =p_inputs.cuda()\r\n",
        "  atk_H = torchattacks.PGD(model_H, eps=10/255, alpha=2/255, steps=4)\r\n",
        "  atk_NH = torchattacks.PGD(model_NH, eps=10/255, alpha=2/255, steps=4)\r\n",
        "  adversarial_images_H = atk_H(inputs, labels)\r\n",
        "  adversarial_images_NH = atk_NH(inputs, labels)\r\n",
        "  adversarial_labels = labels\r\n",
        "  if torch.cuda.is_available():\r\n",
        "        inputs = inputs.cuda()\r\n",
        "        labels = labels.cuda()\r\n",
        "        orig_in=orig_in.cuda()\r\n",
        "        orig_lab=orig_lab.cuda()\r\n",
        "        adversarial_images = adversarial_images.cuda()\r\n",
        "        adversarial_labels = adversarial_labels.cuda()\r\n",
        "        model_NH=model_NH.cuda()\r\n",
        "        model_H=model_H.cuda()\r\n",
        "  accNH = get_accuracy(model_NH(adversarial_images_NH),adversarial_labels,BATCH_SIZE)\r\n",
        "  print(\"accuracy without hessian on adversarial perturbed data\",accNH)\r\n",
        "  print(\"difference in accuracy without hessian\",abs(accNH-get_accuracy(model_NH(orig_in),labels,BATCH_SIZE)))\r\n",
        "  accH = get_accuracy(model_H(adversarial_images_H),adversarial_labels,BATCH_SIZE)\r\n",
        "  print(\"accuracy with hessian on adversarial perturbed data\",accH)\r\n",
        "  print(\"difference in accuracy with hessian\",abs(accH-get_accuracy(model_H(orig_in),labels,BATCH_SIZE)))\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy without hessian on adversarial perturbed data 13.28125\n",
            "difference in accuracy without hessian 79.6875\n",
            "accuracy with hessian on adversarial perturbed data 74.21875\n",
            "difference in accuracy with hessian 7.8125\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DxBYsGuvVfI"
      },
      "source": [
        "**Block below is for perturbing points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7aE90mq7cXb",
        "outputId": "13c1b5ab-7654-42e3-f60a-af40270be730"
      },
      "source": [
        "#code to evaluate the first batch\n",
        "import random\n",
        "for i, data in enumerate(trainloader,0):\n",
        "      inputs, labels = data\n",
        "      if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "      print(type(inputs))\n",
        "      inputs = inputs.view(-1,28, 28)\n",
        "      accNH = get_accuracy(model_NH(inputs),labels,BATCH_SIZE)\n",
        "      print(\"accuracy without hessian on training data\",accNH)\n",
        "      accH = get_accuracy(model_H(inputs),labels,BATCH_SIZE)\n",
        "      print(\"accuracy with hessian on training data\",accH)\n",
        "      break"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "accuracy without hessian on training data 93.75\n",
            "accuracy with hessian on training data 82.03125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfIXJn7V4rpf"
      },
      "source": [
        "def train_p(jacobi,model,N_EPHOCS,lambda_JR):\r\n",
        "    # Model instance\r\n",
        "    for epoch in range(N_EPHOCS+1):  # loop over the dataset multiple times\r\n",
        "        train_running_loss = 0.0\r\n",
        "        train_acc = 0.0\r\n",
        "        model.train()\r\n",
        "        # TRAINING ROUND\r\n",
        "        for i, data in enumerate(trainloader,0):\r\n",
        "            #only train for a single batch for now since its faster\r\n",
        "            if i>=1:\r\n",
        "              break\r\n",
        "             # zero the parameter gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "            # reset hidden states\r\n",
        "            model.hidden = model.init_hidden()\r\n",
        "            \r\n",
        "            # get the inputs\r\n",
        "            inputs, labels = data\r\n",
        "            \r\n",
        "            if torch.cuda.is_available():\r\n",
        "              inputs = inputs.cuda()\r\n",
        "              labels = labels.cuda()\r\n",
        "            inputs = inputs.view(-1,28, 28) \r\n",
        "            inputs.requires_grad = True # this is essential!\r\n",
        "            \r\n",
        "            p_inputs = inputs\r\n",
        "            p_inputs.requires_grad = False\r\n",
        "            p_labels = labels\r\n",
        "            \r\n",
        "            for k in range(p_inputs.shape[0]):\r\n",
        "              #sample set of points and then divide by the norm of it\r\n",
        "              #np.random.seed(1)\r\n",
        "              vecs = np.random.uniform(-1,1,(1,p_inputs.shape[1],p_inputs.shape[2]))\r\n",
        "              #vecs/= np.linalg.norm(vecs)\r\n",
        "              #print(np.linalg.norm(vecs))\r\n",
        "              vecs=vecs\r\n",
        "              #print(vecs)       \r\n",
        "              vecs = torch.from_numpy(vecs).cuda()\r\n",
        "              p_inputs[k] = torch.add(p_inputs[k],vecs)\r\n",
        "              \r\n",
        "            p_inputs = torch.cat((p_inputs,inputs),0)\r\n",
        "            labels = torch.cat((labels,labels))\r\n",
        "            #print(p_inputs.shape)\r\n",
        "            outputs = model(p_inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "               # hessian regularization\r\n",
        "            if not jacobi:\r\n",
        "                total_loss = loss \r\n",
        "                R=0\r\n",
        "            else:\r\n",
        "                R = hessian_penalty(model,z =p_inputs).cuda()\r\n",
        "                total_loss = loss +lambda_JR*(R) # full loss\r\n",
        "\r\n",
        "            total_loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            \r\n",
        "            train_running_loss += loss.detach().item()\r\n",
        "            train_acc += get_accuracy(outputs, labels, 2*BATCH_SIZE)\r\n",
        "        model.eval()\r\n",
        "        #print(i)\r\n",
        "        if epoch%10==0:\r\n",
        "          print('Epoch:  %d | Loss: %.4f |hessian Loss %.4f | Train Accuracy: %.2f' \r\n",
        "                %(epoch, train_running_loss/i,R, train_acc/i))"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xI-eZ5l56D_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "f2722bb4-ca58-4258-878c-da2d8461b44b"
      },
      "source": [
        "optimizer = optim.Adam(model_H.parameters(), lr=0.001)\r\n",
        "train_p(True,model_H,N_EPHOCS=300,lambda_JR=0.05)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | Loss: 0.9565 |hessian Loss 3.6228 | Train Accuracy: 66.41\n",
            "Epoch:  10 | Loss: 1.0154 |hessian Loss 3.0275 | Train Accuracy: 67.19\n",
            "Epoch:  20 | Loss: 0.8405 |hessian Loss 4.6601 | Train Accuracy: 73.44\n",
            "Epoch:  30 | Loss: 0.8756 |hessian Loss 3.9355 | Train Accuracy: 75.00\n",
            "Epoch:  40 | Loss: 0.8651 |hessian Loss 1.8074 | Train Accuracy: 75.78\n",
            "Epoch:  50 | Loss: 0.7768 |hessian Loss 2.4625 | Train Accuracy: 75.78\n",
            "Epoch:  60 | Loss: 0.9314 |hessian Loss 3.0850 | Train Accuracy: 68.75\n",
            "Epoch:  70 | Loss: 0.8355 |hessian Loss 4.2727 | Train Accuracy: 78.12\n",
            "Epoch:  80 | Loss: 0.7590 |hessian Loss 3.1515 | Train Accuracy: 74.22\n",
            "Epoch:  90 | Loss: 0.6608 |hessian Loss 4.9627 | Train Accuracy: 85.16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-a3e90aac1fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_H\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_EPHOCS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_JR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-175-e290c27c6008>\u001b[0m in \u001b[0;36mtrain_p\u001b[0;34m(jacobi, model, N_EPHOCS, lambda_JR)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# TRAINING ROUND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;31m#only train for a single batch for now since its faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_SIGCHLD_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_pids_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefetch_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36m_start_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doing self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... done self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCf7TE_6-LvC"
      },
      "source": [
        "optimizer = optim.Adam(model_NH.parameters(), lr=0.001)\r\n",
        "N_EPHOCS=300\r\n",
        "train_p(False,model_NH,N_EPHOCS,lambda_JR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZvUeZde9DhF",
        "outputId": "1f2196a1-4f43-40cd-90f2-104943c9a4fc"
      },
      "source": [
        "print(\"these are the results after random training\")\r\n",
        "for i, data in enumerate(trainloader,0):\r\n",
        "      if i>=1:\r\n",
        "        break\r\n",
        "      inputs, labels = data\r\n",
        "      if torch.cuda.is_available():\r\n",
        "            inputs = inputs.cuda()\r\n",
        "            labels = labels.cuda()\r\n",
        "      print(type(inputs))\r\n",
        "      inputs = inputs.view(-1,28, 28)\r\n",
        "      accNH = get_accuracy(model_NH(inputs),labels,BATCH_SIZE)\r\n",
        "      print(\"accuracy without hessian on training data\",accNH)\r\n",
        "      accH = get_accuracy(model_H(inputs),labels,BATCH_SIZE)\r\n",
        "      print(\"accuracy with hessian on training data\",accH)\r\n",
        "      "
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "these are the results after random training\n",
            "<class 'torch.Tensor'>\n",
            "accuracy without hessian on training data 92.1875\n",
            "accuracy with hessian on training data 82.03125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQCJUTYxCalx",
        "outputId": "6db0e9d6-aac2-47c7-9e25-b6ac3af35727"
      },
      "source": [
        "from adversairal import torchattacks\r\n",
        "\r\n",
        "for i, data in enumerate(trainloader,0):\r\n",
        "  if i>=1:\r\n",
        "    break\r\n",
        "  torch.backends.cudnn.enabled = False\r\n",
        "  if torch.cuda.is_available():\r\n",
        "        inputs = inputs.cuda()\r\n",
        "        labels = labels.cuda()\r\n",
        "  inputs, labels = data\r\n",
        "  inputs = inputs.view(-1,28, 28) \r\n",
        "  inputs.requires_grad = True # this is essential!\r\n",
        "  atk_H = torchattacks.PGD(model_H, eps=10/255, alpha=2/255, steps=3)\r\n",
        "  atk_NH = torchattacks.PGD(model_NH, eps=10/255, alpha=2/255, steps=3)\r\n",
        "  adversarial_images_H = atk_H(inputs, labels)\r\n",
        "  adversarial_images_NH = atk_NH(inputs, labels)\r\n",
        "  adversarial_labels = labels\r\n",
        "  if torch.cuda.is_available():\r\n",
        "        inputs = inputs.cuda()\r\n",
        "        labels = labels.cuda()\r\n",
        "        adversarial_images_H = adversarial_images_H.cuda()\r\n",
        "        adversarial_images_NH = adversarial_images_NH.cuda()\r\n",
        "        adversarial_labels = adversarial_labels.cuda()\r\n",
        "        model_NH=model_NH.cuda()\r\n",
        "        model_H=model_H.cuda()\r\n",
        "  accNH = get_accuracy(model_NH(adversarial_images_NH),adversarial_labels,BATCH_SIZE)\r\n",
        "  print(\"accuracy without hessian on adversarial data\",accNH)\r\n",
        "  print(\"difference in accuracy without hessian\",abs(accNH-get_accuracy(model_NH(inputs),labels,BATCH_SIZE)))\r\n",
        "  print(\"\\n\")\r\n",
        "  accH = get_accuracy(model_H(adversarial_images_H),adversarial_labels,BATCH_SIZE)\r\n",
        "  print(\"accuracy with hessian on adversarial data\",accH)\r\n",
        "  print(\"difference in accuracy with hessian\",abs(accH-get_accuracy(model_H(inputs),labels,BATCH_SIZE)))\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy without hessian on adversarial data 81.25\n",
            "difference in accuracy without hessian 10.9375\n",
            "\n",
            "\n",
            "accuracy with hessian on adversarial data 79.6875\n",
            "difference in accuracy with hessian 2.34375\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh0k5QMRo9pP"
      },
      "source": [
        "**Plotting the decision boundary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJnF0Eyu7cXb"
      },
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "print(X.shape)\n",
        "print(X[2].shape)\n",
        "\n",
        "m=np.random.randint(0,X.shape[0])\n",
        "print(m)\n",
        "\n",
        "value= X[333]\n",
        "#print(value)\n",
        "h=150\n",
        "n=h**2\n",
        "values=np.array([value for i in range(n)])\n",
        "print(value.shape)\n",
        "def plot_dec_bound(model,axis1,axis2,value,is_reg):\n",
        "    cmap='Paired'\n",
        "    cmap = plt.get_cmap(cmap)\n",
        "    plt.figure()\n",
        "      # step size in the mesh\n",
        "    #create a mesh to plot in\n",
        "    xx, yy = np.meshgrid(np.linspace(-10, 10, h),\n",
        "                       np.linspace(-10,10, h))\n",
        "    data1 = np.c_[xx.ravel(), yy.ravel()]\n",
        "    data=np.reshape(data1,(data1.shape[0],data1.shape[1],1))\n",
        "    meshgrid =[]\n",
        "    value[:,:,axis1]=data[:,0,:]\n",
        "    value[:,:,axis2]=data[:,1,:]\n",
        "    values = torch.from_numpy(value)\n",
        "    print(\"values shape\",values.shape)\n",
        "    if torch.cuda.is_available:\n",
        "      values = values.cuda()\n",
        "    outputs = model(values.float())\n",
        "    #print(\"output has shape\",outputs.shape)\n",
        "    \n",
        "    Z=torch.max(outputs.data, 1)[1].cpu()\n",
        "    Z = Z.numpy()\n",
        "\n",
        "    \n",
        "    print(\"unique values of Z are: \",len(Counter(Z)))\n",
        "  \n",
        "    shapez=Z.shape\n",
        "    #print(\"xx shape:\",xx.shape)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    im=plt.contourf(xx,yy,Z,cmap=\"cool\",alpha = 1)\n",
        "    plt.xlabel(\"axes:%i\"%axis1)\n",
        "    plt.ylabel(\"axes:%i\"%axis2)\n",
        "    plt.title(\"regularized?:\"+(\"true\" if is_reg else \"flase\"))\n",
        "    plt.colorbar(ticks=Z)\n",
        "    if is_reg:\n",
        "        plt.savefig(\"rnn_hess_%i.jpg\"%i)\n",
        "    else:\n",
        "        plt.savefig(\"rnn_%i.jpg\"%i)\n",
        "    plt.show()\n",
        "\n",
        "np.random.seed(19)\n",
        "for i in range(4):\n",
        "    axis1,axis2=np.random.randint(0,values.shape[2]-1,2)\n",
        "    print(\"axes are\",axis1,axis2)\n",
        "    print(\"dec bound without jacobi\")\n",
        "    plot_dec_bound(model_NH,axis1,axis2,values,is_reg=False)\n",
        "    print(\"dec bound with jacobi\")\n",
        "    plot_dec_bound(model_H,axis1,axis2,values,is_reg=True)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTXeQdec7cXc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}